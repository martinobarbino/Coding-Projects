Times:

10 simulations: 0m0.020s
100 simulations: 0m0.022s
1000 simulations: 0m0.027s
10000 simulations: 0m0.083s
100000 simulations: 0m0.646s
1000000 simulations: 0m6.457s

Questions:

Which predictions, if any, proved incorrect as you increased the number of simulations?:

I expected each change in N to increase the run time by a factor of 10.
Instead, in the beginning, each 10x change in N produced an insignificant difference in the run time.
Later on though, as N got to be larger than 10,000 , it appears that each 10x increase in N did increase the run time by a factor of 10.
For example, at 100,000 simulations, the run time was around 0.64 seconds, and at 1,000,000 simulations, the run time increased to 6.4 seconds.

Suppose you're charged a fee for each second of compute time your program uses.
After how many simulations would you call the predictions "good enough"?:

After 100,000 simulations. That way, I would probably be able to avoid paying a fee while still getting a high number of simulations.